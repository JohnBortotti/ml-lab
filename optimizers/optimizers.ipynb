{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cccfc7a3-4214-4d49-bf81-fde78c775efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor\n",
    "from matplotlib import cm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46967788-9c31-4f03-9ecf-da428e920481",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c37bcdf-6abb-4349-87fe-a7626bf58d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, init_position, loss_fn, grad_fn, lr=0.01):\n",
    "        self.position = init_position.clone()\n",
    "        self.loss_fn = loss_fn\n",
    "        self.grad_fn = grad_fn\n",
    "        self.lr = lr\n",
    "        self.trajectory = [init_position.clone()]\n",
    "        self.losses = [self._compute_loss()]\n",
    "    \n",
    "    def _compute_loss(self):\n",
    "        return self.loss_fn(self.position[0].item(), self.position[1].item())\n",
    "    \n",
    "    def step(self):\n",
    "        raise NotImplementedError(\"Subclasses must implement step method\")\n",
    "    \n",
    "    def optimize(self, num_steps=100):\n",
    "        for _ in range(num_steps):\n",
    "            self.step()\n",
    "            self.trajectory.append(self.position.clone())\n",
    "            self.losses.append(self._compute_loss())\n",
    "        return self.position, self.losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6fdead1a-4a5f-4f25-abfe-1c2e405e5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x, y, a=1, b=100):\n",
    "    \"\"\"f(x, y) = (a - x)^2 + b(y - x^2)^2\"\"\"\n",
    "    return (a - x)**2 + b * (y - x**2)**2\n",
    "\n",
    "def rosenbrock_grad(x, y, a=1, b=100):\n",
    "    dx = -2*(a - x) - 4*b*x*(y - x**2)\n",
    "    dy = 2*b*(y - x**2)\n",
    "    return tensor([dx, dy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3060cec8-01fe-4d64-adb4-2ca8c04efeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    def step(self):\n",
    "        gradient = self.grad_fn(self.position[0].item(), self.position[1].item())\n",
    "        self.position -= self.lr * gradient\n",
    "\n",
    "class Momentum(Optimizer):\n",
    "    def __init__(self, init_position, loss_fn, grad_fn, lr=0.01, momentum=0.9):\n",
    "        super().__init__(init_position, loss_fn, grad_fn, lr)\n",
    "        self.momentum = momentum\n",
    "        self.velocity = torch.zeros_like(init_position)\n",
    "    \n",
    "    def step(self):\n",
    "        gradient = self.grad_fn(self.position[0].item(), self.position[1].item())\n",
    "        self.velocity = self.momentum * self.velocity - self.lr * gradient\n",
    "        self.position += self.velocity\n",
    "\n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, init_position, loss_fn, grad_fn, lr=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        super().__init__(init_position, loss_fn, grad_fn, lr)\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = torch.zeros_like(init_position)\n",
    "        self.v = torch.zeros_like(init_position)\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        gradient = self.grad_fn(self.position[0].item(), self.position[1].item())\n",
    "        \n",
    "        # update biased first moment estimate\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * gradient\n",
    "        \n",
    "        # update biased second raw moment estimate\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * gradient**2\n",
    "        \n",
    "        # compute bias-corrected first moment estimate\n",
    "        m_hat = self.m / (1 - self.beta1**self.t)\n",
    "        \n",
    "        # compute bias-corrected second raw moment estimate\n",
    "        v_hat = self.v / (1 - self.beta2**self.t)\n",
    "        \n",
    "        # update parameters\n",
    "        self.position -= self.lr * m_hat / (torch.sqrt(v_hat) + self.epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e50cdf77-7c0b-4286-831e-f0c4e53fadfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: Final position = tensor([-0.9127,  0.8410]), Final loss = 3.664728\n",
      "Momentum: Final position = tensor([0.2936, 0.0817]), Final loss = 0.501033\n",
      "Adam: Final position = tensor([-0.8887,  0.7992]), Final loss = 3.576109\n"
     ]
    }
   ],
   "source": [
    "init_position = tensor([-1.0, 1.0])\n",
    "\n",
    "num_steps=100\n",
    "\n",
    "sgd = SGD(init_position, rosenbrock, rosenbrock_grad, lr=0.001)\n",
    "final_pos, final_loss = sgd.optimize(num_steps=num_steps)\n",
    "print(f\"{sgd.__class__.__name__}: Final position = {final_pos}, Final loss = {final_loss:.6f}\")\n",
    "\n",
    "momentum = Momentum(init_position, rosenbrock, rosenbrock_grad, lr=0.001)\n",
    "final_pos, final_loss = momentum.optimize(num_steps=num_steps)\n",
    "print(f\"{momentum.__class__.__name__}: Final position = {final_pos}, Final loss = {final_loss:.6f}\")\n",
    "\n",
    "adam = Adam(init_position, rosenbrock, rosenbrock_grad, lr=0.002)\n",
    "final_pos, final_loss = adam.optimize(num_steps=num_steps)\n",
    "print(f\"{adam.__class__.__name__}: Final position = {final_pos}, Final loss = {final_loss:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
